set max_line_width 200;
--create topic test_topic 16;

stream1 :=
(bridge from
    test_topic
    partitions = 16
    props = ()
)
-> (project
    key as pk,
    json_int("v0",val) as v0,
    json_float("v1",val) as v1,
    json_bool("v2",val) as v2,
    to_decimal(json_string("v3", val),38,6) as v3,
    json_string("v4", val) as v4,
    to_bytes(json_string("v5", val)) as v5,
    parse_date(json_string("v6", val), "2006-01-02 15:04:05.999999") as v6)
-> (store table by pk);

--load data dataset_1;

(scan all from stream1) -> (sort by pk);

-- load more data;

--load data dataset_2;

(scan all from stream1) -> (sort by pk);

delete(stream1);

--delete topic test_topic;

-- composite key;

--create topic test_topic 16;

stream1 :=
(bridge from
    test_topic
    partitions = 16
    props = ()
)
-> (project
    key as pk,
    json_int("v0",val) as v0,
    json_float("v1",val) as v1,
    json_bool("v2",val) as v2,
    to_decimal(json_string("v3", val),38,6) as v3,
    json_string("v4", val) as v4,
    to_bytes(json_string("v5", val)) as v5,
    parse_date(json_string("v6", val), "2006-01-02 15:04:05.999999") as v6)
-> (store table by pk, v0);

--load data dataset_3;

(scan all from stream1) -> (sort by pk, v0);

delete(stream1);

--delete topic test_topic;

--- with continuation;

--create topic test_topic 16;

stream1 :=
(bridge from
    test_topic
    partitions = 16
    props = ()
)
-> (project
    key as pk,
    json_int("v0",val) as v0,
    json_float("v1",val) as v1,
    json_bool("v2",val) as v2,
    to_decimal(json_string("v3", val),38,6) as v3,
    json_string("v4", val) as v4,
    to_bytes(json_string("v5", val)) as v5,
    parse_date(json_string("v6", val), "2006-01-02 15:04:05.999999") as v6)
-> (store stream);

stream2 := stream1 -> (store table by pk);

stream3 := stream1 -> (store table by pk);

--load data dataset_1;

(scan all from stream2) -> (sort by pk);

(scan all from stream3) -> (sort by pk);

-- check data there after restart;
--restart cluster;
set max_line_width 200;

(scan all from stream2) -> (sort by pk);

(scan all from stream3) -> (sort by pk);

-- errors;

-- try and create stream with table as not the last operator, should fail;

should_fail := stream1 -> (store table by pk) -> (store stream);

delete(stream3);
delete(stream2);
delete(stream1);

--delete topic test_topic;

-- use an empty key for the table - this means only a single row is maintained - this is useful for storing results of
-- aggregations which don't group by any keys;

--create topic test_topic 16;

stream1 :=
(bridge from
    test_topic
    partitions = 16
    props = ()
)
-> (project
    key as pk,
    json_int("v0",val) as v0,
    json_float("v1",val) as v1,
    json_bool("v2",val) as v2,
    to_decimal(json_string("v3", val),38,6) as v3,
    json_string("v4", val) as v4,
    to_bytes(json_string("v5", val)) as v5,
    parse_date(json_string("v6", val), "2006-01-02 15:04:05.999999") as v6)
-> (store table);

--load data dataset_4;

(scan all from stream1) -> (sort by pk);

delete(stream1);

-- errors;

stream1 :=
(bridge from
    test_topic
    partitions = 16
    props = ()
) -> (store table by foo);

--delete topic test_topic;